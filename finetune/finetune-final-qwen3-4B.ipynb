{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "id": "tzwfkPce4Vgj",
    "outputId": "91a448a5-6389-4362-bf3a-6f6f7471f637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in ./venVan/lib/python3.12/site-packages (2025.4.7)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.4.4 in ./venVan/lib/python3.12/site-packages (from unsloth) (2025.4.4)\n",
      "Requirement already satisfied: torch>=2.4.0 in ./venVan/lib/python3.12/site-packages (from unsloth) (2.6.0)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in ./venVan/lib/python3.12/site-packages (from unsloth) (0.0.29.post3)\n",
      "Requirement already satisfied: bitsandbytes in ./venVan/lib/python3.12/site-packages (from unsloth) (0.45.5)\n",
      "Requirement already satisfied: triton>=3.0.0 in ./venVan/lib/python3.12/site-packages (from unsloth) (3.2.0)\n",
      "Requirement already satisfied: packaging in ./venVan/lib/python3.12/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: tyro in ./venVan/lib/python3.12/site-packages (from unsloth) (0.9.19)\n",
      "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in ./venVan/lib/python3.12/site-packages (from unsloth) (4.51.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in ./venVan/lib/python3.12/site-packages (from unsloth) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in ./venVan/lib/python3.12/site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in ./venVan/lib/python3.12/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./venVan/lib/python3.12/site-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in ./venVan/lib/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in ./venVan/lib/python3.12/site-packages (from unsloth) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in ./venVan/lib/python3.12/site-packages (from unsloth) (1.6.0)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 in ./venVan/lib/python3.12/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in ./venVan/lib/python3.12/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: protobuf<4.0.0 in ./venVan/lib/python3.12/site-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in ./venVan/lib/python3.12/site-packages (from unsloth) (0.31.1)\n",
      "Requirement already satisfied: hf_transfer in ./venVan/lib/python3.12/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in ./venVan/lib/python3.12/site-packages (from unsloth) (0.33.1)\n",
      "Requirement already satisfied: torchvision in ./venVan/lib/python3.12/site-packages (from unsloth) (0.21.0)\n",
      "Requirement already satisfied: pyyaml in ./venVan/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venVan/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\n",
      "Requirement already satisfied: filelock in ./venVan/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venVan/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venVan/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./venVan/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venVan/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
      "Requirement already satisfied: xxhash in ./venVan/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venVan/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in ./venVan/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venVan/lib/python3.12/site-packages (from huggingface_hub->unsloth) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in ./venVan/lib/python3.12/site-packages (from huggingface_hub->unsloth) (1.1.0)\n",
      "Requirement already satisfied: networkx in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: setuptools in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (80.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venVan/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venVan/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venVan/lib/python3.12/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venVan/lib/python3.12/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.1)\n",
      "Requirement already satisfied: rich in ./venVan/lib/python3.12/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\n",
      "Requirement already satisfied: cut_cross_entropy in ./venVan/lib/python3.12/site-packages (from unsloth_zoo>=2025.4.4->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pillow in ./venVan/lib/python3.12/site-packages (from unsloth_zoo>=2025.4.4->unsloth) (11.0.0)\n",
      "Requirement already satisfied: msgspec in ./venVan/lib/python3.12/site-packages (from unsloth_zoo>=2025.4.4->unsloth) (0.19.0)\n",
      "Requirement already satisfied: importlib-metadata in ./venVan/lib/python3.12/site-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in ./venVan/lib/python3.12/site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in ./venVan/lib/python3.12/site-packages (from tyro->unsloth) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in ./venVan/lib/python3.12/site-packages (from tyro->unsloth) (4.4.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venVan/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (3.11.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venVan/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venVan/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venVan/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venVan/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.4.26)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venVan/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venVan/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venVan/lib/python3.12/site-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venVan/lib/python3.12/site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venVan/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venVan/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venVan/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venVan/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venVan/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venVan/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venVan/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venVan/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venVan/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venVan/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (1.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venVan/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venVan/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iY9iCU4a4Vgk"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLEkejTT4Vgl",
    "outputId": "39d6d80f-6ee3-4503-ffb4-ea47da74c2c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/administrator/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvanlethai12042002\u001b[0m (\u001b[33mvanlethai12042002-ton-duc-thang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"YOUR_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiDP-JwQ4Vgm",
    "outputId": "f87b9168-f26d-4136-a626-32621bd4a4d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/VanIT/venVan/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"YOUR_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NGRapqx4Vgn",
    "outputId": "e572ad25-fbb7-467b-fe5c-5b33cfda60f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A30. Num GPUs = 2. Max memory: 23.486 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"thailevann/Qwen3-4B_model_CT_DVCQG_v1\",\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = True,\n",
    "    load_in_8bit = False,\n",
    "    full_finetuning = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_05as9pp4Vgn"
   },
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "dataset = load_dataset(\"thailevann/DVCQG_finetune_QA\", split = \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qjnxs2Uj4Vgp"
   },
   "outputs": [],
   "source": [
    "dataset_without_reasoning = dataset.filter(\n",
    "    lambda x: (x.get(\"reason\") or \"\").strip() == \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C28ogRDh4Vgr"
   },
   "outputs": [],
   "source": [
    "def convert_conversations_to_chat_format_non_reasoning(examples):\n",
    "    question = examples.get(\"instruction\", \"\").strip()\n",
    "    answer = examples.get(\"output\", \"\").strip()\n",
    "\n",
    "    # Bỏ nếu thiếu nội dung\n",
    "    if not question or not answer:\n",
    "        return {\"conversation\": []}\n",
    "\n",
    "    # Format prompt thân thiện\n",
    "    user_prompt = f\"\"\"Bạn là một trợ lý AI hỗ trợ tra cứu dịch vụ công. Hãy trả lời câu hỏi dưới đây:\n",
    "## Câu hỏi:\n",
    "{question}\"\"\"\n",
    "\n",
    "    chat_conversations = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    return {\"conversation\": chat_conversations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlLL_UTE4Vgu"
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(dataset_without_reasoning):\n",
    "    if (\n",
    "        item is None\n",
    "        or not isinstance(item, dict)\n",
    "        or \"instruction\" not in item\n",
    "        or \"output\" not in item\n",
    "        or not isinstance(item[\"instruction\"], str)\n",
    "        or not isinstance(item[\"output\"], str)\n",
    "    ):\n",
    "        print(f\"❌ Lỗi tại index {i}: {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzfv3vTX4Vgu"
   },
   "outputs": [],
   "source": [
    "converted_data_non_reasoning = [convert_conversations_to_chat_format_non_reasoning(data) for data in dataset_without_reasoning]\n",
    "dataset_without_reasoning = Dataset.from_list(converted_data_non_reasoning )\n",
    "dataset_without_reasoning = standardize_sharegpt(dataset_without_reasoning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5u5RFEf4Vgu"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset_without_reasoning = dataset_without_reasoning.filter(lambda example: len(example[\"conversation\"]) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8r30ZkBW4Vgu"
   },
   "outputs": [],
   "source": [
    "print(f\"Số lượng mẫu còn lại: {len(dataset_without_reasoning)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zOwzNQJ4Vgv"
   },
   "outputs": [],
   "source": [
    "non_reasoning_conversations = tokenizer.apply_chat_template(\n",
    "    dataset_without_reasoning[\"conversation\"],\n",
    "    tokenize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrmOp6Ga4Vgv",
    "outputId": "df37e32f-4af1-4c91-bd5b-7c15faab7528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nBạn là một trợ lý AI hỗ trợ tra cứu dịch vụ công. Hãy trả lời câu hỏi dưới đây:\\n## Câu hỏi:\\nTra cứu danh mục các TTHC thực hiện tại Bộ phận một cửa Bộ Xây dựng bằng cách nào?<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nCác TTHC được thực hiện tại Bộ phận một cửa được công bố trong Quyết định số 1269/QĐ-BXD ngày 09/10/2018 của Bộ trưởng Bộ Xây dựng về việc công bố danh mục TTHC thực hiện tiếp nhận và trả kết quả tại BPMC của Bộ Xây dựng (được công khai trên Cổng thông tin điện tử Bộ Xây dựng tại địa chỉ www.moc.gov.vn)<|im_end|>\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_reasoning_conversations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jj75jQpl4Vgw",
    "outputId": "b171f609-6e5b-4269-d06a-ee46d46170fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnon_reasoning_subset = non_reasoning_subset.sample(\\n    int(len(reasoning_conversations) * (1.0 - chat_percentage)),\\n    random_state = 2407,\\n)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "non_reasoning_subset = pd.Series(non_reasoning_conversations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GW8oju54Vgw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.Series(non_reasoning_subset)\n",
    "\n",
    "data.name = \"text\"\n",
    "\n",
    "from datasets import Dataset\n",
    "combined_dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "combined_dataset = combined_dataset.shuffle(seed = 3407)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f6pGeJD4Vgw",
    "outputId": "4f83bb87-e945-4a78-8294-b70daceb98b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 61439\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JFaiQvF4Vgw",
    "outputId": "877d1cca-3ace-4a2f-b073-e4fb4b87a083"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <|im_start|>user\\nBạn là một trợ lý AI hỗ trợ ...\n",
       "1    <|im_start|>user\\nBạn là một trợ lý AI hỗ trợ ...\n",
       "2    <|im_start|>user\\nBạn là một trợ lý AI hỗ trợ ...\n",
       "3    <|im_start|>user\\nBạn là một trợ lý AI hỗ trợ ...\n",
       "4    <|im_start|>user\\nBạn là một trợ lý AI hỗ trợ ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aftf9-1A4Vgw",
    "outputId": "4c7d7aa2-0469-441c-f6aa-041608027092"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/administrator/VanIT/wandb/run-20250703_092827-98lr721d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/98lr721d' target=\"_blank\">Qwen3-4B-CT-SFT_dvcqg_v4</a></strong> to <a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc' target=\"_blank\">https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/98lr721d' target=\"_blank\">https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/98lr721d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/98lr721d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ecb8740dc10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use wandb\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"Chatbot-dvc\",\n",
    "    name=\"Qwen3-4B-CT-SFT_dvcqg_v4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYqoYhXL4Vgx",
    "outputId": "262f5973-b745-4a33-ded2-304dea9187bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=16): 100%|█| 61439/61439 [00:16<00:00, 36\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=combined_dataset,\n",
    "    eval_dataset=None,\n",
    "    args=SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs=1,\n",
    "        warmup_steps=100,\n",
    "        learning_rate = 2e-6 ,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"./checkpoints\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=10,\n",
    "        save_total_limit=2,\n",
    "        #fp16=True,\n",
    "        bf16 = True,\n",
    "        fp16 = False,\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5e6a7qs44Vgy",
    "outputId": "387abb95-496f-4d24-df51-c150c66f6196"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 61,439 | Num Epochs = 1 | Total steps = 1,920\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 264,241,152/4,000,000,000 (6.61% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1920' max='1920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1920/1920 5:46:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.541400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.491200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.963400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.967400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.916800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.850500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.846200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.823800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.871500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.821600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.808700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.827100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.814200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.832200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.799200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.773500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.741900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.754200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.761600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.815200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.760800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.785100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.775200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.740900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.795900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.776300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.820500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.770800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.751600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.741600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.728800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.774600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.722000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.722700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.749700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.789500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.807300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.753400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.742300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.722200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.722700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.819600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.730300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.724400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.750800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.760900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.751300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.756300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.797800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.785600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.778100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.765800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.741100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.725800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.741700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.770300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.730400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.688500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.727200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.729800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.742600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.729400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.726800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.762300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.730900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.692200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.758700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.702900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.770900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.713900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>0.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.736600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>0.744200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.750700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.797100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.755400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.748800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.765200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.733300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.724600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.793400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.764200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.764900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.745400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.748500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.689000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>0.739100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.726500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.694900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.661900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>0.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>0.706400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>0.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.696600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>0.724100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.785100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>0.757700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.757500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.716500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>0.777600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.701700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>0.740900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.722200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>0.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.743300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>0.741600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.743200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>0.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>0.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>0.705800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.705600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adapter_model.safetensors: 100%|███████████| 2.61G/2.61G [02:31<00:00, 17.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/thailevann/Qwen3-4B_SFT_dvcqg_v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer.json: 100%|██████████████████████| 11.4M/11.4M [00:00<00:00, 17.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Push bản cuối cùng (optional nếu bạn dùng \"every_save\")\n",
    "model.push_to_hub(\"thailevann/Qwen3-4B_SFT_dvcqg_v4\")\n",
    "tokenizer.push_to_hub(\"thailevann/Qwen3-4B_SFT_dvcqg_v4\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
