{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca4ef4-e178-49aa-9e81-e81675b5035f",
   "metadata": {
    "id": "afca4ef4-e178-49aa-9e81-e81675b5035f"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb3bda-f724-4d40-90c4-704707d3d06b",
   "metadata": {
    "id": "2feb3bda-f724-4d40-90c4-704707d3d06b"
   },
   "outputs": [],
   "source": [
    "!pip install unsloth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fb829-c4c1-4865-b26b-3e7da30472e2",
   "metadata": {
    "id": "bd9fb829-c4c1-4865-b26b-3e7da30472e2"
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
    "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "!pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed97d5-94fa-4630-9e70-89a3f53732f3",
   "metadata": {
    "id": "a6ed97d5-94fa-4630-9e70-89a3f53732f3",
    "outputId": "ad279972-f214-44f8-ca14-abd3a72bdf55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "True\n",
      "NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda2825-e429-48c2-8ed3-8926711230d2",
   "metadata": {
    "id": "dbda2825-e429-48c2-8ed3-8926711230d2",
    "outputId": "e5cc7eda-75aa-4876-ddcd-1a747f1b305a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/VanIT/venVan/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A30. Num GPUs = 2. Max memory: 23.486 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88061181-2f92-4c37-b9cb-ccbe66f7ae20",
   "metadata": {
    "id": "88061181-2f92-4c37-b9cb-ccbe66f7ae20",
    "outputId": "026ceb8b-b3cd-43bf-9dad-0a9c0024f160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading input_embeddings to disk to save VRAM\n",
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
      "Unsloth: Training lm_head in mixed precision to save VRAM\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "\n",
    "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32bb3a7-b1a6-4077-a6f2-8e83af232e09",
   "metadata": {
    "id": "c32bb3a7-b1a6-4077-a6f2-8e83af232e09",
    "outputId": "bcae6540-2aea-4ab7-cef1-9b65d6e3a1c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 18903it [00:03, 4793.86it/s]\n",
      "Generating train split: 18903 examples [00:00, 172688.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = load_dataset(\"thailevann/pretrain_dvcqg\", split=\"train\", streaming=True)\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "with open(\"formatted_dataset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for example in tqdm(dataset, desc=\"Processing\"):\n",
    "        text = example[\"text\"] + EOS_TOKEN\n",
    "        json.dump({\"text\": text}, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"formatted_dataset.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef9522-c634-4c81-91de-b35cf7637324",
   "metadata": {
    "id": "44ef9522-c634-4c81-91de-b35cf7637324",
    "outputId": "88c54e9a-1a51-437a-d275-da0d2d91894d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18903"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67224f94-b4ae-4f56-9e92-6fe0caed6c96",
   "metadata": {
    "id": "67224f94-b4ae-4f56-9e92-6fe0caed6c96"
   },
   "outputs": [],
   "source": [
    "# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu test\n",
    "#dataset_test = load_dataset(\"thailevann/GovServices_Pretrain_Text_v2\", split=\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcda43-cb4d-43c5-b941-fbf1b46b780d",
   "metadata": {
    "id": "60fcda43-cb4d-43c5-b941-fbf1b46b780d",
    "outputId": "d4129ca8-267e-4007-e544-667e6e2a1980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "**T√™n th·ªß t·ª•c**: ƒêƒÉng k√Ω l·∫ßn ƒë·∫ßu ƒë·ªëi v·ªõi t·ªï ch·ª©c h·ªó tr·ª£ nghi√™n c·ª©u c√≥ ho·∫°t ƒë·ªông ph√¢n t√≠ch th·ªëng k√™ v√† qu·∫£n l√Ω d·ªØ li·ªáu nghi√™n c·ª©u th·ª≠ nghi·ªám l√¢m s√†ng\n",
      "**C∆° quan c√¥ng b·ªë**: B·ªô Y t·∫ø\n",
      "**Lƒ©nh v·ª±c**: Khoa h·ªçc, c√¥ng ngh·ªá v√† ƒë√†o t·∫°o\n",
      "**C∆° quan th·ª±c hi·ªán**: C·ª•c Khoa h·ªçc C√¥ng ngh·ªá v√† ƒê√†o t·∫°o - B·ªô Y t·∫ø; C·ª•c Khoa h·ªçc C√¥ng ngh·ªá v√† ƒê√†o t·∫°o - B·ªô Y t·∫ø\n",
      "\n",
      "**Tr√¨nh t·ª± th·ª±c hi·ªán**:\n",
      "T·ªï ch·ª©c ƒëƒÉng k√Ω ho·∫°t ƒë·ªông gi√°m s√°t nghi√™n c·ª©u th·ª≠ nghi·ªám l√¢m s√†ng n·ªôp h·ªì s∆° v·ªÅ B·ªô Y t·∫ø.\n",
      "Khi nh·∫≠n h·ªì s∆°, c∆° quan ti·∫øp nh·∫≠n h·ªì s∆° g·ª≠i cho t·ªï ch·ª©c phi·∫øu ti·∫øp nh·∫≠n h·ªì s∆° theo m·∫´u 04 k√®m theo Th√¥ng t∆∞ n√†y, h∆∞·ªõng d·∫´n b·ªï sung h·ªì s∆° ch∆∞a h·ª£p l·ªá.\n",
      "Trong th·ªùi h·∫°n 20 ng√†y l√†m vi·ªác k·ªÉ t·ª´ ng√†y nh·∫≠n ƒë·ªß h·ªì s∆° h·ª£p l·ªá, B·ªô Y t·∫ø (C·ª•c Khoa h·ªçc c√¥ng ngh·ªá v√† ƒê√†o t·∫°o) c√≥ tr√°ch nhi·ªám xem x√©t, c√≥ vƒÉn b·∫£n ch·∫•p thu·∫≠n ho·∫°t ƒë·ªông h·ªó tr·ª£ nghi√™n c·ª©u th·ª≠ nghi·ªám l√¢m s√†ng. Trong tr∆∞·ªùng h·ª£p kh√¥ng ch·∫•p thu·∫≠n, B·ªô Y t·∫ø (C·ª•c Khoa h·ªçc c√¥ng ngh·ªá v√† ƒê√†o t·∫°o) ph·∫£i c√≥ th√¥ng b√°o b·∫±ng vƒÉn b·∫£n trong ƒë√≥ n√™u r√µ l√Ω do kh√¥ng ch·∫•p thu·∫≠n.<|im_end|>\n",
      "=========================\n",
      "**T√™n th·ªß t·ª•c**: Th·ªß t·ª•c c·∫•p l·∫°i Gi·∫•y x√°c nh·∫≠n ƒë·ªß ƒëi·ªÅu ki·ªán t∆∞ v·∫•n H·ªá th·ªëng qu·∫£n l√Ω ch·∫•t l∆∞·ª£ng theo ti√™u chu·∫©n qu·ªëc gia TCVN ISO 9001:2008 ƒë·ªëi v·ªõi c∆° quan, t·ªï ch·ª©c thu·ªôc h·ªá th·ªëng h√†nh ch√≠nh nh√† n∆∞·ªõc cho chuy√™n gia t∆∞ v·∫•n ƒë·ªôc l·∫≠p\n",
      "**C∆° quan c√¥ng b·ªë**: B·ªô Khoa h·ªçc  v√†  C√¥ng ngh·ªá\n",
      "**Lƒ©nh v·ª±c**: Ti√™u chu·∫©n ƒëo l∆∞·ªùng ch·∫•t l∆∞·ª£ng\n",
      "**C∆° quan th·ª±c hi·ªán**: T·ªïng c·ª•c Ti√™u chu·∫©n ƒêo l∆∞·ªùng Ch·∫•t l∆∞·ª£ng - B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá; T·ªïng c·ª•c Ti√™u chu·∫©n ƒêo l∆∞·ªùng Ch·∫•t l∆∞·ª£ng - B·ªô Khoa h·ªçc v√† C√¥ng ngh·ªá\n",
      "\n",
      "**Tr√¨nh t·ª± th·ª±c hi·ªán**:\n",
      "****B∆∞·ªõc 1****: Ti·∫øp nh·∫≠n h·ªì s∆°\n",
      "Tr∆∞·ªõc khi h·∫øt h·∫°n hi·ªáu l·ª±c c·ªßa Gi·∫•y x√°c nh·∫≠n 02 (hai) th√°ng n·∫øu c√° nh√¢n c√≥ nhu c·∫ßu c·∫•p l·∫°i Gi·∫•y x√°c nh·∫≠n v√† th·∫ª chuy√™n giatham gia ho·∫°t ƒë·ªông t∆∞ v·∫•n ƒë·ªôc l·∫≠p H·ªá th·ªëng qu·∫£n l√Ω ch·∫•t l∆∞·ª£ng ƒë·ªëi v·ªõi c∆° quan, t·ªï ch·ª©c thu·ªôc h·ªá th·ªëng h√†nh ch√≠nh nh√† n∆∞·ªõc chu·∫©n b·ªã h·ªì s∆° theo quy ƒë·ªãnh.\n",
      "N·ªôp h·ªì s∆° tr·ª±c ti·∫øp t·∫°i T·ªïng c·ª•c Ti√™u chu·∫©n ƒêo l∆∞·ªùng Ch·∫•t l∆∞·ª£ng, ho·∫∑c qua ƒë∆∞·ªùng b∆∞u ƒëi·ªán.\n",
      "****Th·ªùi gian ti·∫øp nh·∫≠n h·ªì s∆°****: S√°ng t·ª´ 08 gi·ªù ƒë·∫øn 12 gi·ªù v√† chi·ªÅu t·ª´ 13 gi·ªù ƒë·∫øn 17 gi·ªù v√†o ng√†y l√†m vi·ªác trong tu·∫ßn (th·ª© b·∫£y, ch·ªß nh·∫≠t v√† ng√†y l·ªÖ ngh·ªâ)\n",
      "****B∆∞·ªõc 2****: X·ª≠ l√Ω h·ªì s∆°\n",
      "L√£nh ƒë·∫°o T·ªïng c·ª•c giao cho V·ª• chuy√™n m√¥n v√† L√£nh ƒë·∫°o V·ª• chuy√™n m√¥n s·∫Ω giao c√°n b·ªô x·ª≠ l√Ω h·ªì s∆°\n",
      "C√°n b·ªô ƒë∆∞·ª£c giao x·ª≠ l√Ω h·ªì s∆° xem x√©t t√≠nh h·ª£p l·ªá c·ªßa h·ªì s∆°.\n",
      "Trong th·ªùi h·∫°n 05 (nƒÉm) ng√†y l√†m vi·ªác k·ªÉ t·ª´ ng√†y nh·∫≠n ƒë∆∞·ª£c h·ªì s∆° ƒëƒÉng k√Ω, n·∫øu h·ªì s∆° kh√¥ng ƒë·∫ßy ƒë·ªß theo quy ƒë·ªãnh, c√° nh√¢n ƒëƒÉng k√Ω s·∫Ω ƒë∆∞·ª£c th√¥ng b√°o ƒë·ªÅ ngh·ªã b·ªï sung h·ªì s∆°. Sau th·ªùi h·∫°n 15 (m∆∞·ªùi lƒÉm) ng√†y l√†m vi·ªác k·ªÉ t·ª´ ng√†y ƒë∆∞·ª£c th√¥ng b√°o ƒë·ªÅ ngh·ªã b·ªï sung m√† h·ªì s∆° ƒëƒÉng k√Ω kh√¥ng ƒë∆∞·ª£c b·ªï sung ƒë·∫ßy ƒë·ªß theo quy ƒë·ªãnh, T·ªïng c·ª•c Ti√™u chu·∫©n ƒêo l∆∞·ªùng Ch·∫•t l∆∞·ª£ng c√≥ quy·ªÅn h·ªßy b·ªè vi·ªác x·ª≠ l√Ω ƒë·ªëi v·ªõi h·ªì s∆° n√†y.\n",
      "Trong th·ªùi h·∫°n 15 (m∆∞·ªùi lƒÉm) ng√†y l√†m vi·ªác k·ªÉ t·ª´ khi nh·∫≠n ƒë∆∞·ª£c h·ªì s∆° ƒë·∫ßy ƒë·ªß v√† h·ª£p l·ªá, tr·ª´ tr∆∞·ªùng h·ª£p c·∫ßn thi·∫øt ph·∫£i ƒë√°nh gi√° th·ª±c t·∫ø, T·ªïng c·ª•c Ti√™u chu·∫©n ƒêo l∆∞·ªùng Ch·∫•t l∆∞·ª£ng ti·∫øn h√†nh th·∫©m x√©t h·ªì s∆°, c·∫•p Gi·∫•y x√°c nh·∫≠n ƒë·ªß ƒëi·ªÅu ki·ªán ho·∫°t ƒë·ªông cho cho chuy√™n gia t∆∞ v·∫•n ƒë·ªôc l·∫≠p. Gi·∫•y x√°c nh·∫≠n v√† th·∫ª chuy√™n gia c√≥ hi·ªáu l·ª±c 03 (ba) nƒÉm k·ªÉ t·ª´ ng√†y c·∫•p.\n",
      "****ƒê·ªëi v·ªõi tr∆∞·ªùng h·ª£p c·∫ßn thi·∫øt ph·∫£i ƒë√°nh gi√° th·ª±c t·∫ø, trong th·ªùi h·∫°n 30 (ba m∆∞∆°i) ng√†y l√†m vi·ªác k·ªÉ t·ª´ khi nh·∫≠n ƒë∆∞·ª£c h·ªì s∆°, T·ªïng c·ª•c Ti√™u chu·∫©n ƒêo l∆∞·ªùng Ch·∫•t l∆∞·ª£ng ti·∫øn h√†nh th·∫©m x√©t h·ªì s∆°, c·ª≠ chuy√™n gia ho·∫∑c th√†nh l·∫≠p ƒëo√†n ƒë√°nh gi√° ƒë·ªÉ t·ªï ch·ª©c ƒë√°nh gi√° th·ª±c t·∫ø theo c√°c n·ªôi dung sau****: \n",
      "S·ª± tu√¢n th·ªß quy ƒë·ªãnh ph√°p lu·∫≠t c·ªßa c√° nh√¢n trong lƒ©nh v·ª±c t∆∞ v·∫•n;\n",
      "T√≠nh x√°c th·ª±c c·ªßa c√°c h·ªì s∆° ƒëƒÉng k√Ω;\n",
      "Ho·∫°t ƒë·ªông kh√°c c√≥ li√™n quan t·ªõi lƒ©nh v·ª±c ƒëƒÉng k√Ω.\n",
      "Chi ph√≠ ph·ª•c v·ª• ho·∫°t ƒë·ªông ƒë√°nh gi√° c·ªßa chuy√™n gia ho·∫∑c ƒëo√†n ƒë√°nh gi√° do c√° nh√¢n ƒëƒÉng k√Ω c·∫•p Gi·∫•y x√°c nh·∫≠n b·∫£o ƒë·∫£m.\n",
      "CƒÉn c·ª© h·ªì s∆° ƒëƒÉng k√Ω v√† Bi√™n b·∫£n ƒë√°nh gi√° th·ª±c t·∫ø, T·ªïng c·ª•c c·∫•p Gi·∫•y x√°c nh·∫≠n v√† th·∫ª cho c√°c chuy√™n gia t∆∞ v·∫•n, n·∫øu c√° nh√¢n ƒë√°p ·ª©ng y√™u c·∫ßu. Gi·∫•y x√°c nh·∫≠n v√† th·∫ª chuy√™n gia c√≥ hi·ªáu l·ª±c 03 (ba) nƒÉm k·ªÉ t·ª´ ng√†y c·∫•p.\n",
      "T·ªïng c·ª•c ra quy·∫øt ƒë·ªãnh c·∫•p Gi·∫•y x√°c nh·∫≠n v√† th·∫ª cho c√°c chuy√™n gia t∆∞ v·∫•n ƒë·ªôc l·∫≠p. Tr∆∞·ªùng h·ª£p kh√¥ng ƒë√°p ·ª©ng y√™u c·∫ßu, trong th·ªùi h·∫°n quy ƒë·ªãnh, c√° nh√¢n ƒë∆∞·ª£c th√¥ng b√°o l√Ω do b·∫±ng vƒÉn b·∫£n.\n",
      "****B∆∞·ªõc 3****: Tr·∫£ k·∫øt qu·∫£\n",
      "Tr·∫£ k·∫øt qu·∫£ tr·ª±c ti·∫øp t·∫°i tr·ª• s·ªü T·ªïng c·ª•c Ti√™u chu·∫©n ƒêo l∆∞·ªùng Ch·∫•t l∆∞·ª£ng ho·∫∑c theo ƒë∆∞·ªùng b∆∞u ƒëi·ªán.<|im_end|>\n",
      "=========================\n",
      "**T√™n th·ªß t·ª•c**: Th·ªß t·ª•c c·∫•p ph√°t kinh ph√≠ ƒë·ªëi v·ªõi c√°c t·ªï ch·ª©c, ƒë∆°n v·ªã tr·ª±c thu·ªôc c√°c B·ªô, ng√†nh\n",
      "**C∆° quan c√¥ng b·ªë**: B·ªô T√†i ch√≠nh\n",
      "**Lƒ©nh v·ª±c**: T√†i ch√≠nh doanh nghi·ªáp\n",
      "**C∆° quan th·ª±c hi·ªán**: C·ª•c T√†i ch√≠nh doanh nghi·ªáp - B·ªô t√†i ch√≠nh; C·ª•c T√†i ch√≠nh doanh nghi·ªáp - B·ªô t√†i ch√≠nh\n",
      "\n",
      "**Tr√¨nh t·ª± th·ª±c hi·ªán**:\n",
      "****B∆∞·ªõc 1****: C√°c B·ªô, ng√†nh r√† so√°t, th·∫©m ƒë·ªãnh t·ªïng h·ª£p s·ªë li·ªáu ƒë·ªÅ ngh·ªã c·∫•p kinh ph√≠ h·ªó tr·ª£ ƒë√†o t·∫°o, kinh ph√≠ b·∫£o hi·ªÉm v√† 20% kinh ph√≠ gi·∫£m kho√°n theo ƒë·ªãnh m·ª©c lao ƒë·ªông chung c·ªßa c√°c t·ªï ch·ª©c, ƒë∆°n v·ªã tr·ª±c thu·ªôc, c√≥ vƒÉn b·∫£n b√°o c√°o B·ªô T√†i ch√≠nh.\n",
      "****B∆∞·ªõc 2****: B·ªô T√†i ch√≠nh th·∫©m ƒë·ªãnh v√† c·∫•p kinh ph√≠ b·∫±ng l·ªánh chi ti·ªÅn cho c√°c B·ªô, ng√†nh ƒë·ªÉ chi tr·∫£ cho t·ªï ch·ª©c, ƒë∆°n v·ªã c√≥ s·ª≠ d·ª•ng lao ƒë·ªông l√† ng∆∞·ªùi d√¢n t·ªôc thi·ªÉu s·ªë theo quy ƒë·ªãnh c·ªßa Lu·∫≠t ng√¢n s√°ch nh√† n∆∞·ªõc<|im_end|>\n",
      "=========================\n",
      "**T√™n th·ªß t·ª•c**: Th·ªß t·ª•c quy·∫øt to√°n kinh ph√≠ h·ªó tr·ª£\n",
      "**C∆° quan c√¥ng b·ªë**: B·ªô T√†i ch√≠nh\n",
      "**Lƒ©nh v·ª±c**: T√†i ch√≠nh doanh nghi·ªáp\n",
      "**C∆° quan th·ª±c hi·ªán**: C·ª•c T√†i ch√≠nh doanh nghi·ªáp - B·ªô t√†i ch√≠nh; C·ª•c T√†i ch√≠nh doanh nghi·ªáp - B·ªô t√†i ch√≠nh\n",
      "\n",
      "**Tr√¨nh t·ª± th·ª±c hi·ªán**:\n",
      "****ƒê·ªëi v·ªõi ƒë∆°n v·ªã Trung ∆∞∆°ng****: C√°c T·∫≠p ƒëo√†n, T·ªïng c√¥ng ty, c√°c B·ªô, ng√†nh ki·ªÉm tra quy·∫øt to√°n kinh ph√≠ h·ªó tr·ª£ c·ªßa c√°c ƒë∆°n v·ªã v√† t·ªïng h·ª£p g·ª≠i B·ªô T√†i ch√≠nh ƒë·ªÉ theo d√µi, gi√°m s√°t.\n",
      "****ƒê·ªëi v·ªõi c√°c ƒë∆°n v·ªã ƒë·ªãa ph∆∞∆°ng****: S·ªü T√†i ch√≠nh ki·ªÉm tra quy·∫øt to√°n kinh ph√≠ h·ªó tr·ª£ v√† t·ªïng h·ª£p tr√¨nh ·ª¶y ban nh√¢n d√¢n c·∫•p t·ªânh g·ª≠i B·ªô T√†i ch√≠nh ƒë·ªÉ theo d√µi t·ªïng h·ª£p chung.<|im_end|>\n",
      "=========================\n",
      "**T√™n th·ªß t·ª•c**: Th·ªß t·ª•c c·∫•p ph√°t kinh ph√≠ ƒë·ªëi v·ªõi c√°c t·ªï ch·ª©c, ƒë∆°n v·ªã tr·ª±c thu·ªôc ƒë·ªãa ph∆∞∆°ng\n",
      "**C∆° quan c√¥ng b·ªë**: B·ªô T√†i ch√≠nh\n",
      "**Lƒ©nh v·ª±c**: T√†i ch√≠nh doanh nghi·ªáp\n",
      "**C∆° quan th·ª±c hi·ªán**: S·ªü T√†i ch√≠nh; S·ªü T√†i ch√≠nh\n",
      "\n",
      "**Tr√¨nh t·ª± th·ª±c hi·ªán**:\n",
      "****B∆∞·ªõc 1****: C√°c t·ªï ch·ª©c, ƒë∆°n v·ªã c√≥ s·ª≠ d·ª•ng lao ƒë·ªông l√† ng∆∞·ªùi d√¢n t·ªôc thi·ªÉu s·ªë b√°o c√°o S·ªü T√†i ch√≠nh s·ªë kinh ph√≠ ng√¢n s√°ch Trung ∆∞∆°ng h·ªó tr·ª£\n",
      "****B∆∞·ªõc 2****: S·ªü T√†i ch√≠nh ch·ªß tr√¨, ph·ªëi h·ª£p v·ªõi v·ªõi c√°c S·ªü, ng√†nh li√™n quan th·∫©m ƒë·ªãnh tr√¨nh ·ª¶y ban nh√¢n d√¢n c·∫•p t·ªânh quy·∫øt ƒë·ªãnh. Tr√™n c∆° s·ªü ƒë√≥, S·ªü T√†i ch√≠nh c·∫•p b·∫±ng l·ªánh chi ti·ªÅn cho c√°c t·ªï ch·ª©c, ƒë∆°n v·ªã c√≥ s·ª≠ d·ª•ng lao ƒë·ªông l√† ng∆∞·ªùi d√¢n t·ªôc thi·ªÉu s·ªë. Ri√™ng ƒë·ªëi v·ªõi kinh ph√≠ h·ªó tr·ª£ b·∫£o hi·ªÉm x√£ h·ªôi, b·∫£o hi·ªÉm y t·∫ø, b·∫£o hi·ªÉm th·∫•t nghi·ªáp, S·ªü T√†i ch√≠nh th·ª±c hi·ªán c·∫•p cho t·ªï ch·ª©c, ƒë∆°n v·ªã c√≥ s·ª≠ d·ª•ng lao ƒë·ªông l√† ng∆∞·ªùi d√¢n t·ªôc thi·ªÉu s·ªë, ƒë·ªìng th·ªùi thay t·ªï ch·ª©c, ƒë∆°n v·ªã chuy·ªÉn s·ªë kinh ph√≠ tr·ª±c ti·∫øp cho c∆° quan b·∫£o hi·ªÉm v√† th√¥ng b√°o cho t·ª´ng ƒë∆°n v·ªã sau khi ƒë√£ chuy·ªÉn s·ªë kinh ph√≠ h·ªó tr·ª£ cho c∆° quan b·∫£o hi·ªÉm.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "for row in dataset[:5][\"text\"]:\n",
    "    print(\"=========================\")\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ef6e7-dc0e-43bf-b726-69927d47277b",
   "metadata": {
    "id": "264ef6e7-dc0e-43bf-b726-69927d47277b"
   },
   "outputs": [],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89330ad1-5962-4863-8fef-913d5acf16fa",
   "metadata": {
    "id": "89330ad1-5962-4863-8fef-913d5acf16fa",
    "outputId": "8862b996-b95f-4a7e-8d89-54827187abf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/administrator/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvanlethai12042002\u001b[0m (\u001b[33mvanlethai12042002-ton-duc-thang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"YOUR_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda45684-d0c8-4763-8ed7-9a721a96beef",
   "metadata": {
    "id": "bda45684-d0c8-4763-8ed7-9a721a96beef",
    "outputId": "d76e9a06-84cb-4034-e096-6cf08f184c22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/administrator/VanIT/wandb/run-20250628_111459-fln1gm81</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/fln1gm81' target=\"_blank\">Qwen3-4b-CT-dvcqg-v1</a></strong> to <a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc' target=\"_blank\">https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/fln1gm81' target=\"_blank\">https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/fln1gm81</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vanlethai12042002-ton-duc-thang-university/Chatbot-dvc/runs/fln1gm81?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ae4585f2120>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use wandb\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"Chatbot-dvc\",\n",
    "    name=\"Qwen3-4b-CT-dvcqg-v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e4e42-6424-4655-a8bd-e8cc6deab689",
   "metadata": {
    "id": "a84e4e42-6424-4655-a8bd-e8cc6deab689",
    "outputId": "e48ff84a-b0fb-42ca-c0bb-633c1236b39c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|‚ñà| 18903/18903 [00:10<00:00, 178\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 16,\n",
    "\n",
    "        num_train_epochs = 2,\n",
    "        learning_rate = 1e-5,\n",
    "        embedding_learning_rate = 2e-6,\n",
    "        warmup_ratio = 0.1,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        #fp16 = not is_bfloat16_supported(),\n",
    "        #bf16 = is_bfloat16_supported(),\n",
    "        bf16 = True,\n",
    "        fp16 = False,\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"wandb\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb18e9-0360-480f-a7d7-8f7269821568",
   "metadata": {
    "id": "69eb18e9-0360-480f-a7d7-8f7269821568",
    "outputId": "0c0f732d-17f3-49ae-b494-67341ae99180"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 18,903 | Num Epochs = 2 | Total steps = 294\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 16 x 1) = 128\n",
      " \"-____-\"     Trainable parameters = 1,042,153,472/4,000,000,000 (26.05% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [294/294 4:32:29, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.408500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.214100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.989400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.963400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.887300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.887100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.880900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.860600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.818700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.794400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.759600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.762300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.758200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.750200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.737700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [03:29<00:00, 209.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/thailevann/Qwen3-4B_model_CT_DVCQG_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\n",
      "tokenizer.json:   0%|                               | 0.00/11.4M [00:00<?, ?B/s]\u001b[A\n",
      "tokenizer.json:  14%|‚ñà‚ñà‚ñà                   | 1.62M/11.4M [00:00<00:00, 11.6MB/s]\u001b[A\n",
      "tokenizer.json:  24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2.79M/11.4M [00:01<00:04, 2.15MB/s]\u001b[A\n",
      "tokenizer.json:  38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 4.31M/11.4M [00:01<00:02, 3.09MB/s]\u001b[A\n",
      "tokenizer.json:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 6.05M/11.4M [00:01<00:01, 4.02MB/s]\u001b[A\n",
      "tokenizer.json:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 8.36M/11.4M [00:01<00:00, 5.25MB/s]\u001b[A\n",
      "tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.4M/11.4M [00:02<00:00, 4.41MB/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"YOUR_KEY\")\n",
    "model.push_to_hub(\"thailevann/Qwen3-4B_model_CT_DVCQG_v1\")\n",
    "tokenizer.push_to_hub(\"thailevann/Qwen3-4B_model_CT_DVCQG_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d00003-a97a-453a-983d-e8f524c5b564",
   "metadata": {
    "id": "83d00003-a97a-453a-983d-e8f524c5b564"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
